{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9909406,"sourceType":"datasetVersion","datasetId":6088534}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:41:29.068999Z","iopub.execute_input":"2024-11-14T20:41:29.069403Z","iopub.status.idle":"2024-11-14T20:41:40.441289Z","shell.execute_reply.started":"2024-11-14T20:41:29.069352Z","shell.execute_reply":"2024-11-14T20:41:40.440271Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import BertTokenizer, BertModel\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nfrom torch.optim import AdamW \nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:38:49.527391Z","iopub.execute_input":"2024-11-14T20:38:49.528039Z","iopub.status.idle":"2024-11-14T20:38:53.245839Z","shell.execute_reply.started":"2024-11-14T20:38:49.527991Z","shell.execute_reply":"2024-11-14T20:38:53.244856Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Load the dataset\ndata = pd.read_excel('/kaggle/input/data-set/5247-rows_3-Emotions_No-Type.xlsx')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:38:55.658579Z","iopub.execute_input":"2024-11-14T20:38:55.659768Z","iopub.status.idle":"2024-11-14T20:38:56.560970Z","shell.execute_reply.started":"2024-11-14T20:38:55.659724Z","shell.execute_reply":"2024-11-14T20:38:56.560184Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Extract input (Utterance) and target (Emotion)\nX = data['Utterance'].values\ny = data['Emotion'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:38:59.740217Z","iopub.execute_input":"2024-11-14T20:38:59.740733Z","iopub.status.idle":"2024-11-14T20:38:59.745703Z","shell.execute_reply.started":"2024-11-14T20:38:59.740695Z","shell.execute_reply":"2024-11-14T20:38:59.744601Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Label encode 'Emotion' with new values [-1, 0, 1]\nlabel_encoder_emotion = LabelEncoder()\ny = label_encoder_emotion.fit_transform(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:39:03.127004Z","iopub.execute_input":"2024-11-14T20:39:03.127664Z","iopub.status.idle":"2024-11-14T20:39:03.132627Z","shell.execute_reply.started":"2024-11-14T20:39:03.127624Z","shell.execute_reply":"2024-11-14T20:39:03.131558Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Label encode 'Dialogue_Act'\nlabel_encoder_dialogue_act = LabelEncoder()\ndialogue_act_encoded = label_encoder_dialogue_act.fit_transform(data['Dialogue_Act'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:39:08.204878Z","iopub.execute_input":"2024-11-14T20:39:08.205581Z","iopub.status.idle":"2024-11-14T20:39:08.211588Z","shell.execute_reply.started":"2024-11-14T20:39:08.205540Z","shell.execute_reply":"2024-11-14T20:39:08.210721Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Set device to GPU if available, otherwise CPU\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:40:41.741740Z","iopub.execute_input":"2024-11-14T20:40:41.742165Z","iopub.status.idle":"2024-11-14T20:40:41.796617Z","shell.execute_reply.started":"2024-11-14T20:40:41.742125Z","shell.execute_reply":"2024-11-14T20:40:41.795486Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Initialize BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:40:42.829923Z","iopub.execute_input":"2024-11-14T20:40:42.830822Z","iopub.status.idle":"2024-11-14T20:40:43.166499Z","shell.execute_reply.started":"2024-11-14T20:40:42.830779Z","shell.execute_reply":"2024-11-14T20:40:43.165539Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Tokenize the data\ndef tokenize_data(text_list):\n    return tokenizer(\n        text_list,\n        padding=True,\n        truncation=True,\n        max_length=128,\n        return_tensors='pt'\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:40:44.085487Z","iopub.execute_input":"2024-11-14T20:40:44.086475Z","iopub.status.idle":"2024-11-14T20:40:44.090900Z","shell.execute_reply.started":"2024-11-14T20:40:44.086432Z","shell.execute_reply":"2024-11-14T20:40:44.090004Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# PyTorch Dataset Class\nclass EmotionDataset(Dataset):\n    def __init__(self, encodings, dialogue_act, labels):\n        self.encodings = encodings\n        self.dialogue_act = dialogue_act\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['dialogue_act'] = torch.tensor(self.dialogue_act[idx], dtype=torch.long)\n        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:40:45.661714Z","iopub.execute_input":"2024-11-14T20:40:45.662471Z","iopub.status.idle":"2024-11-14T20:40:45.669550Z","shell.execute_reply.started":"2024-11-14T20:40:45.662430Z","shell.execute_reply":"2024-11-14T20:40:45.668565Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Custom BERT Model with Embeddings for Dialogue Act\nclass BertWithAdditionalFeatures(nn.Module):\n    def __init__(self, bert_model, dialogue_act_vocab_size, embedding_dim, num_labels):\n        super(BertWithAdditionalFeatures, self).__init__()\n        self.bert = bert_model\n        self.dialogue_act_embedding = nn.Embedding(dialogue_act_vocab_size, embedding_dim)\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(bert_model.config.hidden_size + embedding_dim, num_labels)\n\n    def forward(self, input_ids, attention_mask, dialogue_act):\n        # Get BERT embeddings\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs[1]\n\n        # Get embedding for Dialogue Act\n        dialogue_act_embedded = self.dialogue_act_embedding(dialogue_act)\n\n        # Concatenate BERT output with Dialogue Act embeddings\n        combined_output = torch.cat((pooled_output, dialogue_act_embedded), dim=1)\n\n        # Pass through fully connected layer\n        output = self.fc(self.dropout(combined_output))\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:40:54.297493Z","iopub.execute_input":"2024-11-14T20:40:54.298161Z","iopub.status.idle":"2024-11-14T20:40:54.306651Z","shell.execute_reply.started":"2024-11-14T20:40:54.298117Z","shell.execute_reply":"2024-11-14T20:40:54.305682Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Training parameters\nbatch_size = 16\nlearning_rate = 5e-5\nmax_epochs = 3\nn_splits = 5\npatience = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:41:23.783964Z","iopub.execute_input":"2024-11-14T20:41:23.784322Z","iopub.status.idle":"2024-11-14T20:41:23.788844Z","shell.execute_reply.started":"2024-11-14T20:41:23.784290Z","shell.execute_reply":"2024-11-14T20:41:23.787916Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Initialize K-Fold cross-validator\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\nfold_accuracies = []\nbest_accuracy = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:42:07.058418Z","iopub.execute_input":"2024-11-14T20:42:07.059354Z","iopub.status.idle":"2024-11-14T20:42:07.064225Z","shell.execute_reply.started":"2024-11-14T20:42:07.059308Z","shell.execute_reply":"2024-11-14T20:42:07.063286Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Start cross-validation\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"\\nStarting Fold {fold + 1}/{n_splits}\")\n    \n    # Split data for the current fold\n    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n    dialogue_act_train_fold, dialogue_act_val_fold = dialogue_act_encoded[train_idx], dialogue_act_encoded[val_idx]\n\n    # Tokenize the data\n    train_encodings = tokenize_data(X_train_fold.astype(str).tolist())\n    val_encodings = tokenize_data(X_val_fold.astype(str).tolist())\n\n    # Prepare datasets and data loaders\n    train_dataset = EmotionDataset(train_encodings, dialogue_act_train_fold, y_train_fold)\n    val_dataset = EmotionDataset(val_encodings, dialogue_act_val_fold, y_val_fold)\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    # Initialize model\n    bert_model = BertModel.from_pretrained('bert-base-uncased')\n    model = BertWithAdditionalFeatures(\n        bert_model=bert_model,\n        dialogue_act_vocab_size=len(label_encoder_dialogue_act.classes_),\n        embedding_dim=16,\n        num_labels=len(label_encoder_emotion.classes_)\n    ).to(device)\n\n    # Initialize optimizer and criterion\n    optimizer = AdamW(model.parameters(), lr=learning_rate)  # AdamW from torch.optim\n    criterion = nn.CrossEntropyLoss()\n\n    # Early stopping initialization\n    best_val_loss = float('inf')\n    patience_counter = 0\n\n    for epoch in range(max_epochs):\n        print(f\"\\nEpoch {epoch + 1}/{max_epochs}\")\n\n        # Training phase\n        model.train()\n        train_loss = 0\n        for batch in tqdm(train_loader):\n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            optimizer.zero_grad()\n            outputs = model(\n                input_ids=batch['input_ids'],\n                attention_mask=batch['attention_mask'],\n                dialogue_act=batch['dialogue_act']\n            )\n            loss = criterion(outputs, batch['labels'])\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        # Calculate average training loss\n        train_loss /= len(train_loader)\n        print(f\"Training Loss: {train_loss:.4f}\")\n\n        # Validation phase\n        model.eval()\n        val_loss = 0\n        predictions, true_labels = [], []\n        with torch.no_grad():\n            for batch in val_loader:\n                batch = {k: v.to(device) for k, v in batch.items()}\n                outputs = model(\n                    input_ids=batch['input_ids'],\n                    attention_mask=batch['attention_mask'],\n                    dialogue_act=batch['dialogue_act']\n                )\n\n                loss = criterion(outputs, batch['labels'])\n                val_loss += loss.item()\n\n                logits = outputs\n                predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n                true_labels.extend(batch['labels'].cpu().numpy())\n\n        # Calculate average validation loss and accuracy\n        val_loss /= len(val_loader)\n        accuracy = accuracy_score(true_labels, predictions)\n        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.4f}\")\n\n        # Check for early stopping\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0  # Reset the patience counter\n            best_model_state = model.state_dict()  # Save best model\n        else:\n            patience_counter += 1\n\n        if patience_counter >= patience:\n            print(\"Early stopping triggered.\")\n            break\n\n    # Load the best model state\n    model.load_state_dict(best_model_state)\n    fold_accuracies.append(accuracy)\n\n    # Update best accuracy\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T20:42:34.678191Z","iopub.execute_input":"2024-11-14T20:42:34.679159Z","iopub.status.idle":"2024-11-14T21:06:57.931492Z","shell.execute_reply.started":"2024-11-14T20:42:34.679112Z","shell.execute_reply":"2024-11-14T21:06:57.930477Z"}},"outputs":[{"name":"stdout","text":"\nStarting Fold 1/5\n\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:26<00:00,  3.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.4156\nValidation Loss: 0.3988, Validation Accuracy: 0.8343\n\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.3125\nValidation Loss: 0.3536, Validation Accuracy: 0.8552\n\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.2233\nValidation Loss: 0.3973, Validation Accuracy: 0.8419\n\nStarting Fold 2/5\n\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.4250\nValidation Loss: 0.3370, Validation Accuracy: 0.8743\n\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.3272\nValidation Loss: 0.3287, Validation Accuracy: 0.8705\n\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.2302\nValidation Loss: 0.3926, Validation Accuracy: 0.8714\n\nStarting Fold 3/5\n\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.4032\nValidation Loss: 0.3820, Validation Accuracy: 0.8580\n\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.3135\nValidation Loss: 0.3554, Validation Accuracy: 0.8656\n\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.2258\nValidation Loss: 0.3892, Validation Accuracy: 0.8541\n\nStarting Fold 4/5\n\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.4154\nValidation Loss: 0.3791, Validation Accuracy: 0.8618\n\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.2944\nValidation Loss: 0.3760, Validation Accuracy: 0.8532\n\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.1979\nValidation Loss: 0.5081, Validation Accuracy: 0.8437\n\nStarting Fold 5/5\n\nEpoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.4081\nValidation Loss: 0.3672, Validation Accuracy: 0.8694\n\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.3033\nValidation Loss: 0.4157, Validation Accuracy: 0.8513\n\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 263/263 [01:28<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training Loss: 0.2145\nValidation Loss: 0.4570, Validation Accuracy: 0.8608\nEarly stopping triggered.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Print cross-validation results\naverage_accuracy = np.mean(fold_accuracies)\nprint(f\"\\nCross-Validation Accuracy: {average_accuracy:.4f}\")\nprint(f\"Best Accuracy achieved: {best_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:14:06.195357Z","iopub.execute_input":"2024-11-14T21:14:06.196361Z","iopub.status.idle":"2024-11-14T21:14:06.201637Z","shell.execute_reply.started":"2024-11-14T21:14:06.196320Z","shell.execute_reply":"2024-11-14T21:14:06.200729Z"}},"outputs":[{"name":"stdout","text":"\nCross-Validation Accuracy: 0.8544\nBest Accuracy achieved: 0.8714\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Re-tokenize the full test set (assuming `X_test` and `y_test` are set aside initially)\nX_test = data['Utterance'].values  # Replace with your actual test data\ny_test = label_encoder_emotion.transform(data['Emotion'].values)  # Replace with actual test data labels\ndialogue_act_test = label_encoder_dialogue_act.transform(data['Dialogue_Act'])  # Test set dialogue acts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:16:10.445654Z","iopub.execute_input":"2024-11-14T21:16:10.446583Z","iopub.status.idle":"2024-11-14T21:16:10.455018Z","shell.execute_reply.started":"2024-11-14T21:16:10.446536Z","shell.execute_reply":"2024-11-14T21:16:10.454007Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Tokenize the test set\ntest_encodings = tokenize_data(X_test.astype(str).tolist())\ntest_dataset = EmotionDataset(test_encodings, dialogue_act_test, y_test)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:16:16.794526Z","iopub.execute_input":"2024-11-14T21:16:16.795398Z","iopub.status.idle":"2024-11-14T21:16:21.796461Z","shell.execute_reply.started":"2024-11-14T21:16:16.795345Z","shell.execute_reply":"2024-11-14T21:16:21.795354Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":" #Load the best-performing model state from cross-validation\nmodel.load_state_dict(best_model_state)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:16:35.583800Z","iopub.execute_input":"2024-11-14T21:16:35.584596Z","iopub.status.idle":"2024-11-14T21:16:35.608045Z","shell.execute_reply.started":"2024-11-14T21:16:35.584552Z","shell.execute_reply":"2024-11-14T21:16:35.607200Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"BertWithAdditionalFeatures(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dialogue_act_embedding): Embedding(59, 16)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (fc): Linear(in_features=784, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Evaluate on test set\nmodel.eval()\ntest_predictions, test_true_labels = [], []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(\n            input_ids=batch['input_ids'],\n            attention_mask=batch['attention_mask'],\n            dialogue_act=batch['dialogue_act']\n        )\n\n        logits = outputs\n        test_predictions.extend(torch.argmax(logits, dim=-1).cpu().numpy())\n        test_true_labels.extend(batch['labels'].cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:16:46.399758Z","iopub.execute_input":"2024-11-14T21:16:46.400506Z","iopub.status.idle":"2024-11-14T21:17:23.926961Z","shell.execute_reply.started":"2024-11-14T21:16:46.400465Z","shell.execute_reply":"2024-11-14T21:17:23.926122Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Calculate test accuracy and classification report\ntest_accuracy = accuracy_score(test_true_labels, test_predictions)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n\ntarget_names = [str(class_) for class_ in label_encoder_emotion.classes_]\ntest_report = classification_report(test_true_labels, test_predictions, target_names=target_names)\nprint(test_report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T21:18:11.828193Z","iopub.execute_input":"2024-11-14T21:18:11.828863Z","iopub.status.idle":"2024-11-14T21:18:11.856814Z","shell.execute_reply.started":"2024-11-14T21:18:11.828820Z","shell.execute_reply":"2024-11-14T21:18:11.855776Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9421\n              precision    recall  f1-score   support\n\n          -1       0.90      0.87      0.88      1070\n           0       0.95      0.98      0.97      4098\n           1       1.00      0.04      0.07        79\n\n    accuracy                           0.94      5247\n   macro avg       0.95      0.63      0.64      5247\nweighted avg       0.94      0.94      0.94      5247\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\n\n# Load BART model and tokenizer for summarization\nbart_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\nbart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:42:43.293054Z","iopub.execute_input":"2024-11-14T22:42:43.293488Z","iopub.status.idle":"2024-11-14T22:42:44.956033Z","shell.execute_reply.started":"2024-11-14T22:42:43.293440Z","shell.execute_reply":"2024-11-14T22:42:44.955001Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"def summarize_text(utterance):\n    if len(utterance.split()) > 30:  \n        inputs = bart_tokenizer(utterance, max_length=1024, return_tensors='pt', truncation=True)\n        \n        summary_ids = bart_model.generate(\n            inputs['input_ids'], \n            max_length=60,\n            min_length=25,\n            length_penalty=2.0,\n            num_beams=8,\n            temperature=0.7,\n            do_sample=True,      \n            early_stopping=True\n        )\n        return bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return utterance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:43:29.622157Z","iopub.execute_input":"2024-11-14T22:43:29.623084Z","iopub.status.idle":"2024-11-14T22:43:29.629073Z","shell.execute_reply.started":"2024-11-14T22:43:29.623040Z","shell.execute_reply":"2024-11-14T22:43:29.628112Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"def predict_emotion(utterance, dialogue_act):\n    # Save the original utterance\n    original_utterance = utterance\n\n    # Summarize the utterance if it is too long (more than 30 words)\n    summarized_utterance = summarize_text(utterance)\n\n    # Tokenize and encode the summarized (or original) utterance\n    utterance_encoding = tokenize_data([summarized_utterance])\n    encoded_dialogue_act = torch.tensor(label_encoder_dialogue_act.transform([dialogue_act]), dtype=torch.long)\n\n    # Move data to the appropriate device (GPU or CPU)\n    input_ids = utterance_encoding['input_ids'].to(device)\n    attention_mask = utterance_encoding['attention_mask'].to(device)\n    dialogue_act = encoded_dialogue_act.to(device)\n\n    # Perform model prediction\n    model.eval()\n    with torch.no_grad():\n        output = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            dialogue_act=dialogue_act\n        )\n\n        # Get the predicted emotion (from logits)\n        predicted_emotion_idx = torch.argmax(output, dim=1).cpu().numpy()[0]\n        predicted_emotion = label_encoder_emotion.inverse_transform([predicted_emotion_idx])[0]\n\n    # Return both the original and summarized utterance along with the predicted emotion\n    return original_utterance, summarized_utterance, predicted_emotion","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:43:30.658932Z","iopub.execute_input":"2024-11-14T22:43:30.659644Z","iopub.status.idle":"2024-11-14T22:43:30.667221Z","shell.execute_reply.started":"2024-11-14T22:43:30.659603Z","shell.execute_reply":"2024-11-14T22:43:30.666258Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"# Example usage\nnew_sample = {\n    \"Utterance\": \"I’ve had a lot on my plate lately, both personally and professionally. I’ve been trying to stay on top of everything, but sometimes it feels like it’s just too much. My schedule has been packed, and I’ve had very little time to relax or take a break. I know I need to manage my time better and take care of my mental health, but it’s hard to find that balance. I feel like I’m constantly running from one task to the next.\",\n    \"Dialogue_Act\": \"od\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:43:31.428619Z","iopub.execute_input":"2024-11-14T22:43:31.429456Z","iopub.status.idle":"2024-11-14T22:43:31.433826Z","shell.execute_reply.started":"2024-11-14T22:43:31.429411Z","shell.execute_reply":"2024-11-14T22:43:31.432879Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"original_utterance, summarized_utterance, predicted_emotion = predict_emotion(new_sample[\"Utterance\"], new_sample[\"Dialogue_Act\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:43:32.157033Z","iopub.execute_input":"2024-11-14T22:43:32.157783Z","iopub.status.idle":"2024-11-14T22:43:40.269632Z","shell.execute_reply.started":"2024-11-14T22:43:32.157743Z","shell.execute_reply":"2024-11-14T22:43:40.268583Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# Display the results\nprint(f\"Original Utterance: {original_utterance}\")\nprint(\"\\n\")\nprint(f\"Summarized Utterance: {summarized_utterance}\")\nprint(\"\\n\")\nprint(f\"Predicted Emotion: {predicted_emotion}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-14T22:43:40.271547Z","iopub.execute_input":"2024-11-14T22:43:40.272131Z","iopub.status.idle":"2024-11-14T22:43:40.282359Z","shell.execute_reply.started":"2024-11-14T22:43:40.272081Z","shell.execute_reply":"2024-11-14T22:43:40.281058Z"}},"outputs":[{"name":"stdout","text":"Original Utterance: I’ve had a lot on my plate lately, both personally and professionally. I’ve been trying to stay on top of everything, but sometimes it feels like it’s just too much. My schedule has been packed, and I’ve had very little time to relax or take a break. I know I need to manage my time better and take care of my mental health, but it’s hard to find that balance. I feel like I’m constantly running from one task to the next.\n\n\nSummarized Utterance: I’ve had a lot on my plate lately, both personally and professionally. I feel like I’m constantly running from one task to the next. I know I need to manage my time better and take care of my mental health.\n\n\nPredicted Emotion: -1\n","output_type":"stream"}],"execution_count":75}]}